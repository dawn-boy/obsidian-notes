### Axioms
$$0 \le P(A) \le 1$$
$$P(A) > 0$$
$$\overline{A} = 1-A$$
![[math-1.jpg]]
## Types of events
### 1. Mutually exclusive
- If and only if both the events cannot occur at the same time
- ==Only one occurs and the other doesn't==.
$$A \cap B = 0$$
$$A \cup B = P(A) + P(B) - P(A\cap B) = P(A) + P(B) - 0$$
$$\implies P(A) + P(B)$$
#### addition rule
- the probability that at least one of the two events will occur
$$A\cup B = P(A) + P(B) - P(A\cap B)$$
### 2. Non-mutually exclusive events
- if and only if both the events can occur at the same time
### 3. Dependent events
- If one event can influence the other event
$$P(A\cap B) = P(A) * P(B)$$
$$P(A\cup B) = 0$$
### 4. Independent event
- if one event cannot influence the other event
#### multiplication rule
- the probability that both the events will occur sequentially
$$P(A\cap B) = P(A) * P(B)$$
#### Keywords
A, B, C are their respective winning events,
- if none wins => $\overline{ABC}$
- if at least one lose =>  $\overline{A}BC + A\overline{B}C + AB\overline{C} + \overline{AB}C + A\overline{BC} + \overline{A}B\overline{C} + \overline{ABC}$ or => $1- \overline{ABC}$
- if exactly one lose =>  $\overline{A}BC + A\overline{B}C + AB\overline{C}$
- if exactly one wins => $A\overline{BC}+ \overline{A}B\overline{C} + \overline{AB}{C}$
## combinations and permutations
$$Permutations \implies \frac{n!}{(n-k)!}$$
$$Combinations\implies  nC_k = \frac{n!}{k! * (n-k)!}$$
## Conditional Probability
- it deals with the probability of event occurring given that another event has already occurred.
$$P(A/B) = \frac{P(A\cap B)}{P(B)}$$
$$P(B/A) = \frac{P(A\cap B)}{P(A)}$$
## Bayes Theorem
$$P(A) = \sum\ P(B) * P(A/B)$$
$$P(B/A) = \frac{P(B_{i})\ * P(A/B_i)}{\sum (P(B_{i})\ * P(A/B_i))}$$
$$(1-x)^{-1} = 1+x+x^2+\ ...$$
## Naive Bayes's theorem
- First calculate the prior probability
- use additive smoothing, by adding 1 in the numerator, to give the non-occurred words a chance.  
- to find the probability of a particular event:
	- probability of the event * prior probability 
	

## Random Variable
- a variable whose value is unknown and it assigns values to each of the experiments outcome
### types of random variable
1. discrete
	- Discrete random variable have a countable set of possible values. 
	- Useful of things like quality control.
2. continuous
	- these can take on any value within the range
	- useful of physical measurement and simulations.

## Probability functions
### 1. Probability mass function (PMF)
- describes the likelihood of each possible value for a discrete random variable
$$p_i > 0$$
$$\sum p_i = 1$$
### 2. Probability density function (PDF)
-  captures the range of probability distribution for a continuous random variable
$$f(x) \ge 0$$
$$\int f(x)dx = 1$$
### 3. Cumulative function


### formulas
 $$\int_{0}^{\infty} e^{-x} x^{n-1} = \Gamma{n}$$
 $$Variation \implies V(X) = \sum{x^2}- (\sum x)^2$$
 $$1^{st} moment \implies \sum x = $$
 $$Mean \implies \sum x * P(x)$$
## 2D discrete variables
### joint probability
- 